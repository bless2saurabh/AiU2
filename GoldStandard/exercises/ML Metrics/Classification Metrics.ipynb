{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jN5FSNyF-l8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import logging,sys  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Srds9b1C-l8i"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "5        1  760  3.00     2\n",
       "6        1  560  2.98     1\n",
       "7        0  400  3.08     2\n",
       "8        1  540  3.39     3\n",
       "9        0  700  3.92     2\n",
       "10       0  800  4.00     4\n",
       "11       0  440  3.22     1\n",
       "12       1  760  4.00     1\n",
       "13       0  700  3.08     2\n",
       "14       1  700  4.00     1\n",
       "15       0  480  3.44     3\n",
       "16       0  780  3.87     4\n",
       "17       0  360  2.56     3\n",
       "18       0  800  3.75     2\n",
       "19       1  540  3.81     1\n",
       "20       0  500  3.17     3\n",
       "21       1  660  3.63     2\n",
       "22       0  600  2.82     4\n",
       "23       0  680  3.19     4\n",
       "24       1  760  3.35     2\n",
       "25       1  800  3.66     1\n",
       "26       1  620  3.61     1\n",
       "27       1  520  3.74     4\n",
       "28       1  780  3.22     2\n",
       "29       0  520  3.29     1\n",
       "..     ...  ...   ...   ...\n",
       "370      1  540  3.77     2\n",
       "371      1  680  3.76     3\n",
       "372      1  680  2.42     1\n",
       "373      1  620  3.37     1\n",
       "374      0  560  3.78     2\n",
       "375      0  560  3.49     4\n",
       "376      0  620  3.63     2\n",
       "377      1  800  4.00     2\n",
       "378      0  640  3.12     3\n",
       "379      0  540  2.70     2\n",
       "380      0  700  3.65     2\n",
       "381      1  540  3.49     2\n",
       "382      0  540  3.51     2\n",
       "383      0  660  4.00     1\n",
       "384      1  480  2.62     2\n",
       "385      0  420  3.02     1\n",
       "386      1  740  3.86     2\n",
       "387      0  580  3.36     2\n",
       "388      0  640  3.17     2\n",
       "389      0  640  3.51     2\n",
       "390      1  800  3.05     2\n",
       "391      1  660  3.88     2\n",
       "392      1  600  3.38     3\n",
       "393      1  620  3.75     2\n",
       "394      1  460  3.99     3\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_dataset= []\n",
    "target = []\n",
    "\n",
    "data_frame = pd.read_csv(\"binary.csv\",header=0)\n",
    "data_frame\n",
    "\n",
    "#Target coloumn name: 'admit' having values as 0 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BpmozV37-l8m"
   },
   "outputs": [],
   "source": [
    "dataset = np.array(data_frame)\n",
    "# Sepratating out target column from rest of data-set columns\n",
    "for row in dataset:\n",
    "    extracted_dataset.append(row[1:])\n",
    "    target.append(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1550820926305,
     "user": {
      "displayName": "Saurabh Bansal",
      "photoUrl": "",
      "userId": "16730173580197411311"
     },
     "user_tz": -330
    },
    "id": "qxl40W6k-l8p",
    "outputId": "07874a75-fd81-41a5-9e46-6ba5447f32c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  320\n",
      "Testing dataset size:  80\n"
     ]
    }
   ],
   "source": [
    "#Splitting independent data and targeted data as test and train\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(extracted_dataset,\n",
    "                                                   target,test_size=0.2,\n",
    "                                                   random_state=100)\n",
    "\n",
    "print (\"Training dataset size: \", len(X_train))\n",
    "print (\"Testing dataset size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Gn1roYtA-l8t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "\n",
    "clf_entropy=LogisticRegression()\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yTKT-RH6-l8z"
   },
   "outputs": [],
   "source": [
    "#predicting test data values for clf_entropy model\n",
    "predicted_entropy = clf_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1550821426068,
     "user": {
      "displayName": "Saurabh Bansal",
      "photoUrl": "",
      "userId": "16730173580197411311"
     },
     "user_tz": -330
    },
    "id": "jfrKuLOx-l82",
    "outputId": "519442ab-db2f-46b4-be53-47d45dce464e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  49\n",
      "False:  31\n",
      "Accuracy = 61.25%\n"
     ]
    }
   ],
   "source": [
    "# Collecting count of correctly and mis-predicted data\n",
    "idx = 0\n",
    "true = 0\n",
    "false = 0\n",
    "for i in X_test:\n",
    "        if predicted_entropy[idx]==Y_test[idx]:\n",
    "            true +=1\n",
    "        else:\n",
    "            false +=1\n",
    "        idx +=1\n",
    "\n",
    "print (\"True: \", true)\n",
    "print (\"False: \", false)\n",
    "\n",
    "# Accuracy calculation\n",
    "accuracy =  (true/(true+false))\n",
    "print(\"Accuracy = {:.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1550821646883,
     "user": {
      "displayName": "Saurabh Bansal",
      "photoUrl": "",
      "userId": "16730173580197411311"
     },
     "user_tz": -330
    },
    "id": "J1eWxL1M-l87",
    "outputId": "e8a6f758-0210-457b-ec3f-1921f70a19a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  6]\n",
      " [25  1]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from  sklearn.metrics import confusion_matrix \n",
    "cM = confusion_matrix(Y_test,predicted_entropy)\n",
    "print(cM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1550822016991,
     "user": {
      "displayName": "Saurabh Bansal",
      "photoUrl": "",
      "userId": "16730173580197411311"
     },
     "user_tz": -330
    },
    "id": "CwsDYaRB-l8_",
    "outputId": "ae5be2d1-8001-41cd-84bd-7338106a5462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = Sensitivity = 65.75%\n",
      "Specificity = 14.29%\n",
      "Accuracy=61.25%\n",
      "Precision=88.89%\n",
      "f1 score=75.59%\n",
      "auc of ROC curve = 46.37%\n"
     ]
    }
   ],
   "source": [
    "# Calculating metrics using matrix\n",
    "tp, fp, fn, tn = cM.ravel()\n",
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "print(\"Recall = Sensitivity = {:.2%}\".format(tp/(tp+fn)))\n",
    "print(\"Specificity = {:.2%}\".format(tn/(tn+fp)))\n",
    "print(\"Accuracy={:.2%}\".format((tp+tn)/(tp+tn+fp+fn)))\n",
    "print(\"Precision={:.2%}\".format(tp/(tp+fp)))\n",
    "f1score= 2 *(recall*precision)/(precision+recall)\n",
    "print(\"f1 score={:.2%}\".format(f1score))\n",
    "from sklearn.metrics import roc_curve\n",
    "from  sklearn.metrics import auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test,predicted_entropy)\n",
    "aucP=auc(fpr, tpr)\n",
    "\n",
    "print(\"auc of ROC curve = {:.2%}\".format(aucP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FzLI13pr-l9D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ClassificationMetrics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
